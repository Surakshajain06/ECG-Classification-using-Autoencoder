{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "261fd778",
   "metadata": {},
   "source": [
    "Setup (imports, seeds, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008d0a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbad6c8",
   "metadata": {},
   "source": [
    "Load data & label-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "439dcafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw beats shape: (109487, 90, 1)\n",
      "Raw labels dtype: <U1 unique: ['F' 'N' 'Q' 'S' 'V']\n",
      "Saved integer-encoded labels -> ecg_labels_encoded.npy\n",
      "Label classes (index->class): {0: np.str_('F'), 1: np.str_('N'), 2: np.str_('Q'), 3: np.str_('S'), 4: np.str_('V')}\n",
      "Saved binary labels (0=Normal,1=Abnormal) -> ecg_binary_labels.npy\n",
      "Binary counts: normal= 90625 abnormal= 18862\n"
     ]
    }
   ],
   "source": [
    "# Chunk 1: Load data and encode labels\n",
    "NPZ_PATH = \"../src/Preprocessed_data/ecg_data.npz\"   # adjust if needed\n",
    "ENCODED_LABELS_OUT = \"ecg_labels_encoded.npy\"       # saved integer labels\n",
    "BINARY_LABELS_OUT = \"ecg_binary_labels.npy\"         # optional binary 0/1 file\n",
    "\n",
    "data = np.load(NPZ_PATH, allow_pickle=True)\n",
    "beats = data['beats']   # expected shapes: (N, 90), (N, 90, 1) or (N,1,90)\n",
    "labels_raw = data['labels']  # could be strings like 'N','V',... or ints\n",
    "\n",
    "# Make sure string bytes decode properly\n",
    "if labels_raw.dtype.type is np.bytes_:\n",
    "    labels_raw = labels_raw.astype(str)\n",
    "\n",
    "print(\"Raw beats shape:\", beats.shape)\n",
    "print(\"Raw labels dtype:\", labels_raw.dtype, \"unique:\", np.unique(labels_raw)[:10])\n",
    "\n",
    "# 1) Label encode (multi-class)\n",
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(labels_raw)  # integers 0..K-1\n",
    "np.save(ENCODED_LABELS_OUT, labels_encoded)\n",
    "print(\"Saved integer-encoded labels ->\", ENCODED_LABELS_OUT)\n",
    "print(\"Label classes (index->class):\", {i:c for i,c in enumerate(le.classes_)})\n",
    "\n",
    "# 2) Create binary labels (Normal vs Abnormal) if you want binary task\n",
    "#    Convention: 'N' means Normal. If your labels are integer-only and you don't know which int==N,\n",
    "#    use the string labels (labels_raw) or modify map.\n",
    "binary_labels = np.array([0 if str(l) == 'N' else 1 for l in labels_raw])\n",
    "np.save(BINARY_LABELS_OUT, binary_labels)\n",
    "print(\"Saved binary labels (0=Normal,1=Abnormal) ->\", BINARY_LABELS_OUT)\n",
    "print(\"Binary counts: normal=\", int((binary_labels==0).sum()), \"abnormal=\", int((binary_labels==1).sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68311fc6",
   "metadata": {},
   "source": [
    "Stratified split into Train / Val / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "702da4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared beats shape: (109487, 1, 90)\n",
      "Train / Val / Test shapes: (65691, 1, 90) (21898, 1, 90) (21898, 1, 90)\n",
      "Train label counts: [54374 11317]\n",
      "Val   label counts: [18126  3772]\n",
      "Test  label counts: [18125  3773]\n"
     ]
    }
   ],
   "source": [
    "# - For binary classification: use `binary_labels`\n",
    "# - For multiclass classification: use `labels_encoded`\n",
    "\n",
    "USE_BINARY = True   # set False if you want multiclass\n",
    "y_all = binary_labels if USE_BINARY else labels_encoded\n",
    "\n",
    "# Ensure beats shape -> (N, 1, L) for Conv1d\n",
    "if beats.ndim == 2:\n",
    "    beats = beats[:, np.newaxis, :]          # (N,1,L)\n",
    "elif beats.ndim == 3 and beats.shape[-1] == 1:\n",
    "    beats = np.transpose(beats, (0,2,1))     # (N,1,L)\n",
    "# else assume already (N,1,L)\n",
    "\n",
    "print(\"Prepared beats shape:\", beats.shape)\n",
    "\n",
    "# Split: 60% train / 20% val / 20% test (stratified)\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    beats, y_all, test_size=0.20, stratify=y_all, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# from trainval, split 75/25 -> train 60% total, val 20% total\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.25, stratify=y_trainval, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Train / Val / Test shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "print(\"Train label counts:\", np.bincount(y_train))\n",
    "print(\"Val   label counts:\", np.bincount(y_val))\n",
    "print(\"Test  label counts:\", np.bincount(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5567c9",
   "metadata": {},
   "source": [
    "Prepare PyTorch DataLoaders for Autoencoder (train + val only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee2a9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader batches: 257 Val loader batches: 86\n"
     ]
    }
   ],
   "source": [
    "# DataLoaders for AE training (only uses beats, no labels)\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32).to(DEVICE)\n",
    "X_val_t   = torch.tensor(X_val, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "train_ds = TensorDataset(X_train_t)   # AE doesn't need labels\n",
    "val_ds   = TensorDataset(X_val_t)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"Train loader batches:\", len(train_loader), \"Val loader batches:\", len(val_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85ab3ba",
   "metadata": {},
   "source": [
    "Define the 1D Conv Autoencoder (flexible, extractable encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e803de4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE instantiated. Latent dim: 64 Encoder output shape: torch.Size([1, 64, 12])\n"
     ]
    }
   ],
   "source": [
    "# --- Chunk 4 ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Conv1dAutoencoder(nn.Module):\n",
    "    def __init__(self, input_length=90, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.target_len = input_length  # Store for padding/trimming later\n",
    "\n",
    "        # ===== ENCODER =====\n",
    "        self.encoder_conv = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Determine flattened size dynamically\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 1, input_length)\n",
    "            enc_out = self.encoder_conv(dummy)\n",
    "            self._enc_out_shape = enc_out.shape\n",
    "            flat_dim = enc_out.numel()\n",
    "\n",
    "        self.fc_enc = nn.Linear(flat_dim, latent_dim)\n",
    "        self.fc_dec = nn.Linear(latent_dim, flat_dim)\n",
    "\n",
    "        # ===== DECODER =====\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder_conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.fc_enc(x)\n",
    "        return z\n",
    "\n",
    "    def decode(self, z):\n",
    "        x = self.fc_dec(z)\n",
    "        x = x.view(z.size(0), *self._enc_out_shape[1:])\n",
    "        x = self.decoder_conv(x)\n",
    "        # Ensure exact length match\n",
    "        if x.size(-1) > self.target_len:\n",
    "            x = x[..., :self.target_len]\n",
    "        elif x.size(-1) < self.target_len:\n",
    "            pad_amt = self.target_len - x.size(-1)\n",
    "            x = torch.nn.functional.pad(x, (0, pad_amt))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        return self.decode(z)\n",
    "\n",
    "\n",
    "# Define input length from data\n",
    "INPUT_LEN = beats.shape[-1]\n",
    "\n",
    "# Instantiate AE\n",
    "ae = Conv1dAutoencoder(input_length=INPUT_LEN, latent_dim=64).to(DEVICE)\n",
    "print(\"AE instantiated. Latent dim:\", 64, \"Encoder output shape:\", ae._enc_out_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027eaad8",
   "metadata": {},
   "source": [
    "Train the autoencoder (with validation & best-checkpoint save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3707cc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 Train MSE: 0.035765  Val MSE: 0.001683\n",
      "Epoch 02 Train MSE: 0.000986  Val MSE: 0.000585\n",
      "Epoch 03 Train MSE: 0.000501  Val MSE: 0.000390\n",
      "Epoch 04 Train MSE: 0.000380  Val MSE: 0.000477\n",
      "Epoch 05 Train MSE: 0.000320  Val MSE: 0.000255\n",
      "Epoch 06 Train MSE: 0.000267  Val MSE: 0.000224\n",
      "Epoch 07 Train MSE: 0.000246  Val MSE: 0.000267\n",
      "Epoch 08 Train MSE: 0.000214  Val MSE: 0.000181\n",
      "Epoch 09 Train MSE: 0.000215  Val MSE: 0.000167\n",
      "Epoch 10 Train MSE: 0.000183  Val MSE: 0.000902\n",
      "Epoch 11 Train MSE: 0.000183  Val MSE: 0.000158\n",
      "Epoch 12 Train MSE: 0.000209  Val MSE: 0.000135\n",
      "Epoch 13 Train MSE: 0.000139  Val MSE: 0.000129\n",
      "Epoch 14 Train MSE: 0.000146  Val MSE: 0.000156\n",
      "Epoch 15 Train MSE: 0.000137  Val MSE: 0.000249\n",
      "Epoch 16 Train MSE: 0.000174  Val MSE: 0.000089\n",
      "Epoch 17 Train MSE: 0.000098  Val MSE: 0.000082\n",
      "Epoch 18 Train MSE: 0.000110  Val MSE: 0.000075\n",
      "Epoch 19 Train MSE: 0.000100  Val MSE: 0.000068\n",
      "Epoch 20 Train MSE: 0.000108  Val MSE: 0.000064\n",
      "Epoch 21 Train MSE: 0.000078  Val MSE: 0.000058\n",
      "Epoch 22 Train MSE: 0.000077  Val MSE: 0.000053\n",
      "Epoch 23 Train MSE: 0.000082  Val MSE: 0.000084\n",
      "Epoch 24 Train MSE: 0.000075  Val MSE: 0.000044\n",
      "Epoch 25 Train MSE: 0.000082  Val MSE: 0.000238\n",
      "Epoch 26 Train MSE: 0.000054  Val MSE: 0.000040\n",
      "Epoch 27 Train MSE: 0.000051  Val MSE: 0.000047\n",
      "Epoch 28 Train MSE: 0.000061  Val MSE: 0.000100\n",
      "Epoch 29 Train MSE: 0.000050  Val MSE: 0.000041\n",
      "Epoch 30 Train MSE: 0.000060  Val MSE: 0.000031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Chunk 5 ---\n",
    "EPOCHS = 30\n",
    "LR = 1e-3\n",
    "best_val = float('inf')\n",
    "optimizer = optim.Adam(ae.parameters(), lr=LR)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    ae.train()\n",
    "    train_loss = 0.0\n",
    "    for (xb,) in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        recon = ae(xb)\n",
    "        loss = criterion(recon, xb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * xb.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    ae.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for (xb,) in val_loader:\n",
    "            recon = ae(xb)\n",
    "            val_loss += criterion(recon, xb).item() * xb.size(0)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} Train MSE: {train_loss:.6f}  Val MSE: {val_loss:.6f}\")\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        torch.save(ae.state_dict(), \"best_autoencoder.pth\")\n",
    "\n",
    "ae.load_state_dict(torch.load(\"best_autoencoder.pth\", map_location=DEVICE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae57aa3",
   "metadata": {},
   "source": [
    "Extract latent features for train / val / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a432e589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent shapes: (65691, 64) (21898, 64) (21898, 64)\n"
     ]
    }
   ],
   "source": [
    "# Extract latents\n",
    "def extract_latents(model, X_np, batch_size=512):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    ds = TensorDataset(torch.tensor(X_np, dtype=torch.float32))\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
    "    latents = []\n",
    "    with torch.no_grad():\n",
    "        for (xb,) in loader:\n",
    "            xb = xb.to(device)\n",
    "            z = model.encode(xb)  # shape (B, LATENT_DIM)\n",
    "            latents.append(z.cpu().numpy())\n",
    "    return np.vstack(latents)\n",
    "\n",
    "X_train_latent = extract_latents(ae, X_train)\n",
    "X_val_latent   = extract_latents(ae, X_val)\n",
    "X_test_latent  = extract_latents(ae, X_test)\n",
    "\n",
    "print(\"Latent shapes:\", X_train_latent.shape, X_val_latent.shape, X_test_latent.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53a5a77",
   "metadata": {},
   "source": [
    "Scale the latent features (important for many classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93e6fd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved -> latent_scaler.joblib\n"
     ]
    }
   ],
   "source": [
    "#  Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_latent)\n",
    "X_val_scaled   = scaler.transform(X_val_latent)\n",
    "X_test_scaled  = scaler.transform(X_test_latent)\n",
    "\n",
    "# Save scaler for later inference\n",
    "joblib.dump(scaler, \"latent_scaler.joblib\")\n",
    "print(\"Scaler saved -> latent_scaler.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a893b625",
   "metadata": {},
   "source": [
    "Train Random Forest (with simple validation-based tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b148fcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: n_est=100, max_depth=None -> val macro-F1=0.9621\n",
      "Params: n_est=100, max_depth=10 -> val macro-F1=0.9475\n",
      "Params: n_est=100, max_depth=20 -> val macro-F1=0.9606\n",
      "Params: n_est=200, max_depth=None -> val macro-F1=0.9628\n",
      "Params: n_est=200, max_depth=10 -> val macro-F1=0.9465\n",
      "Params: n_est=200, max_depth=20 -> val macro-F1=0.9613\n",
      "Best RF params: {'n_estimators': 200, 'max_depth': None} val macro-F1: 0.9628343066073933\n",
      "Saved best RF -> rf_best.joblib\n"
     ]
    }
   ],
   "source": [
    "# Train RandomForest and tune using validation set\n",
    "import itertools\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "}\n",
    "best_rf = None\n",
    "best_score = -1.0\n",
    "best_params = None\n",
    "\n",
    "for n_est, md in itertools.product(param_grid[\"n_estimators\"], param_grid[\"max_depth\"]):\n",
    "    rf = RandomForestClassifier(n_estimators=n_est, max_depth=md, class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    rf.fit(X_train_scaled, y_train)   # train on train set\n",
    "    val_pred = rf.predict(X_val_scaled)\n",
    "    # choose metric; here F1 (macro) or accuracy â€” choose what matters (we use f1_score macro for imbalanced)\n",
    "    from sklearn.metrics import f1_score\n",
    "    score = f1_score(y_val, val_pred, average='macro')\n",
    "    print(f\"Params: n_est={n_est}, max_depth={md} -> val macro-F1={score:.4f}\")\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_rf = rf\n",
    "        best_params = {\"n_estimators\": n_est, \"max_depth\": md}\n",
    "\n",
    "print(\"Best RF params:\", best_params, \"val macro-F1:\", best_score)\n",
    "joblib.dump(best_rf, \"rf_best.joblib\")\n",
    "print(\"Saved best RF -> rf_best.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b9dc5f",
   "metadata": {},
   "source": [
    "Final evaluation on test set (report & metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b271c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report (test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9773    0.9960    0.9866     18125\n",
      "           1     0.9790    0.8889    0.9318      3773\n",
      "\n",
      "    accuracy                         0.9776     21898\n",
      "   macro avg     0.9782    0.9425    0.9592     21898\n",
      "weighted avg     0.9776    0.9776    0.9771     21898\n",
      "\n",
      "Confusion matrix:\n",
      "[[18053    72]\n",
      " [  419  3354]]\n",
      "Test ROC-AUC: 0.9933185227158484\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test set\n",
    "# Load classifier (we saved best_rf)\n",
    "clf = joblib.load(\"rf_best.joblib\")\n",
    "\n",
    "y_test_pred = clf.predict(X_test_scaled)\n",
    "print(\"Classification report (test):\")\n",
    "print(classification_report(y_test, y_test_pred, digits=4))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# If binary, compute ROC-AUC\n",
    "if len(np.unique(y_all)) == 2:\n",
    "    y_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    print(\"Test ROC-AUC:\", auc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
